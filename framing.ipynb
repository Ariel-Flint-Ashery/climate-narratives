{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pp\n",
    "from claim_verifier import ClaimCheck\n",
    "from contrarian_claims import contrarian_claims_full\n",
    "import os\n",
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "from frame_extractor import FrameExtract\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST A SINGLE ARTICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper = \"telegraph\"\n",
    "verifier = ClaimCheck()\n",
    "#%%\n",
    "# find all articles\n",
    "\n",
    "filename = \"'Greens hindering the global warming fight' Exaggerated claims mislead public, but world still needs.txt\"\n",
    "text = pp.load_text(f\"articles/{newspaper}/txt/{filename}\")\n",
    "date, length, author, title = pp.extract_metadata(text, filename)\n",
    "# Loop through all files in the input folder\n",
    "# filename_list = [filename for filename in os.listdir(input_folder) if filename.endswith(\".txt\")]\n",
    "# df_path = f\"{newspaper}_claims.csv\"\n",
    "# dataframe = pp.load_or_create_df(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentences\n",
    "#sentences = sent_tokenize(text)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this article about climate change?\n",
    "question = \"Does this TEXT discuss climate change?\"\n",
    "answer = verifier.claim_check(text = text, question = question)\n",
    "print(answer==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_claims = {'claims': [], 'claim_ids': []}\n",
    "\n",
    "for claim_id, claim_details in tqdm(contrarian_claims_full.items()):\n",
    "    claim_description = claim_details[\"description\"]\n",
    "    question = f\"Does the TEXT explicitly or implicitly present, discuss, or relate to the following claim: {claim_description}?\"\n",
    "    match = verifier.claim_check(text = text, question = question)\n",
    "    if match:\n",
    "        text_claims['claims'].append(claim_description)\n",
    "        text_claims['claim_ids'].append(claim_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"claim_test.pkl\", 'wb')\n",
    "# pickle.dump(text_claims, f)\n",
    "# f.close()\n",
    "\n",
    "#text_claims = pickle.load(open(\"claim_test.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FX = FrameExtract(claims_file=contrarian_claims_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = {id: {'best_frame': '', 'candidate_frames': []}}\n",
    "for k in range(len(text_claims['claim_ids'])):\n",
    "    if k > 0:\n",
    "        break\n",
    "    claim_description = text_claims['claims'][k]\n",
    "    id = text_claims['claim_ids'][k]\n",
    "\n",
    "    detective_thoughts = []\n",
    "    # generate agent frame detection thought\n",
    "    for agent in range(4):\n",
    "        thought = FX.CoT_detect_framing(article = text, claim = claim_description)\n",
    "        print(thought)\n",
    "        detective_thoughts.append(thought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detective_thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_framing = FX.hivemind_detection(article = text, claim = claim_description, thought_list=detective_thoughts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_explanations = []\n",
    "# generate agent frame explanation thought\n",
    "for agent in range(4):\n",
    "    thought = FX.CoT_explain_framing(article = text, claim = claim_description)\n",
    "    print(thought)\n",
    "    frame_explanations.append(thought)\n",
    "\n",
    "final_explanation = FX.update_explanation(article = text, claim = claim_description, thought_list=frame_explanations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_summaries = []\n",
    "for agent in range(4):\n",
    "    thought = FX.generate_frame_summary(article = text, claim = claim_description, explanation=final_explanation)\n",
    "    print(thought)\n",
    "    candidate_summaries.append(thought)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame = FX.hivemind_choose_best_frame(article = text, claim = claim_description, thought_list = candidate_summaries)\n",
    "print(final_frame)\n",
    "all_frames[id]['best_frame'] = final_frame\n",
    "all_frames[id]['candidate_frames'] = candidate_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
