{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert .RTF files to .docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pypandoc\n",
    "import hashlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_hash(file_path, chunk_size=1024):\n",
    "    \"\"\"Calculate the MD5 hash of a file to identify duplicates by content.\"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def find_duplicates(folder_path):\n",
    "    \"\"\"Identify duplicate .rtf files in a folder based on names and contents.\"\"\"\n",
    "    files_seen = {}\n",
    "    duplicate_files = []\n",
    "\n",
    "    # Regex pattern to match files with (1), (2), etc., like \"file (1).rtf\" or \"file (2).RTF\"\n",
    "    pattern = re.compile(r\"(.*)\\(\\d+\\)\\.rtf$\", re.IGNORECASE)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".rtf\"):\n",
    "            match = pattern.match(filename)\n",
    "            \n",
    "            # If the file matches the duplicate naming pattern\n",
    "            if match:\n",
    "                duplicate_files.append(folder_path+filename)\n",
    "                # Extract the base filename, ignoring the (x) suffix and trimming any extra whitespace\n",
    "                # base_name = match.group(1).strip() + \".rtf\"\n",
    "                # base_name = base_name.lower()  # Ensure consistent lowercase for comparison\n",
    "                # file_path = os.path.join(folder_path, filename)\n",
    "                # base_file_path = os.path.join(folder_path, base_name)\n",
    "\n",
    "                # # Check if the base file (without suffix) has been seen\n",
    "                # if base_name in files_seen:\n",
    "                #     base_file_hash = files_seen[base_name]\n",
    "                #     duplicate_file_hash = file_hash(file_path)\n",
    "                    \n",
    "                #     # Compare hashes to confirm they are duplicates\n",
    "                #     if base_file_hash == duplicate_file_hash:\n",
    "                #         duplicate_files.append(file_path)\n",
    "                # else:\n",
    "                #     # If the original base file exists, calculate and store its hash\n",
    "                #     if os.path.exists(base_file_path):\n",
    "                #         files_seen[base_name] = file_hash(base_file_path)\n",
    "\n",
    "    return duplicate_files\n",
    "\n",
    "def delete_files(file_list):\n",
    "    \"\"\"Delete duplicate files from the system.\"\"\"\n",
    "    for file_path in file_list:\n",
    "        os.remove(file_path)\n",
    "        #print(f\"Deleted: {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper = \"telegraph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete duplicate files\n",
    "# Specify the folder path containing the .RTF files\n",
    "folder_path = rf'articles/{newspaper}/rtf/'\n",
    "\n",
    "# Find and delete duplicates\n",
    "duplicates = find_duplicates(folder_path)\n",
    "delete_files(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input (source) and output (target) folders\n",
    "input_folder = rf'C:/Users/user/Documents/PhD Workspace/climate-narratives/articles/{newspaper}/rtf/'\n",
    "output_folder = rf'C:/Users/user/Documents/PhD Workspace/climate-narratives/articles/{newspaper}/txt/'\n",
    "\n",
    "# Ensure the output folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through all files in the input folder\n",
    "filename_list = [filename for filename in os.listdir(input_folder) if filename.endswith(\".RTF\")]\n",
    "input_path_list = [os.path.join(input_folder, filename) for filename in filename_list]\n",
    "output_path_list = [os.path.join(output_folder, filename.replace(\".RTF\", \".txt\")) for filename in filename_list]\n",
    "\n",
    "for filename, input_path, output_path in zip(filename_list, input_path_list, output_path_list):\n",
    "    if filename.replace(\".RTF\", \".txt\") in os.listdir(output_folder):\n",
    "        continue\n",
    "    try:\n",
    "        pypandoc.convert_file(input_path, 'plain', format='rtf', outputfile=output_path)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if filename.endswith(\".RTF\"):\n",
    "#         input_path = os.path.join(input_folder, filename)\n",
    "#         output_path = os.path.join(output_folder, filename.replace(\".RTF\", \".txt\"))\n",
    "#         #print(\"file found: \", input_path)\n",
    "#         # Convert the RTF file to TXT\n",
    "#         pypandoc.convert_file(input_path, 'plain', format='rtf', outputfile=output_path)\n",
    "#         #print(f\"Converted {filename} to .txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
